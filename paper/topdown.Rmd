---
title             : "Top-down moderators on generic understanding"
shorttitle        : "Top-down moderators on generic understanding"

author: 
  - name          : "Michael Henry Tessler"
    affiliation   : "1"
    corresponding : yes    # Define only one corresponding author
    address       : "450 Serra Mall, Bldg. 420, Rm. 316, Stanford, CA 94305"
    email         : "mhtessler@stanford.edu"
  - name          : "Noah D. Goodman"
    affiliation   : "1"

affiliation:
  - id            : "1"
    institution   : "Department of Psychology, Stanford University"
    
header-includes:
  - \usepackage{tabularx}
  - \usepackage{multicol}
  - \usepackage{wrapfig}
  - \usepackage{caption}
  - \usepackage{booktabs}
  - \usepackage{amsmath}
  - \usepackage{graphicx}
  - \usepackage{subcaption}
  - \usepackage{longtable}
  - \usepackage{array}
  - \usepackage{multirow}
  
author_note: >
  This manuscript is currently in prep. Comments or suggestions should be directed to MH Tessler.

abstract: |
  Enter abstract here. Each new line herein must be indented, like this line.
  
keywords          : "keywords"
wordcount         : "X"

bibliography      : ["generics.bib"]

figsintext        : yes
figurelist        : no
tablelist         : no
footnotelist      : no
lineno            : no
mask              : no

class             : "man"
output            : papaja::apa6_pdf
---
\newcommand{\denote}[1]{\mbox{ $[\![ #1 ]\!]$}}
\newcommand*\diff{\mathop{}\!\mathrm{d}}
\definecolor{Red}{RGB}{255,0,0}
\definecolor{Green}{RGB}{10,200,100}
\definecolor{Blue}{RGB}{10,100,200}

\newcommand{\mht}[1]{{\textcolor{Blue}{[mht: #1]}}}
\newcommand{\ndg}[1]{{\textcolor{Green}{[ndg: #1]}}}
\newcommand{\red}[1]{{\textcolor{Red}{#1}}}


```{r load_packages, include = FALSE}
library(papaja)
library(tidyverse)
library(cowplot)
library(ggthemes)
library(RColorBrewer)
library(ggpirate)
library(brms)
theme_set(theme_few())
```

```{r analysis_preferences}
# Seed for random number generation
set.seed(42)
knitr::opts_chunk$set(echo=FALSE, warning=FALSE, cache=T, message=FALSE, sanitize = T)
```


# Introduction

In the literature on generics, it is long argued that generic meaning cannot be reduced to probabilities or quantification [@Carlson1977; @Carlson1995; @Gelman2007; @Leslie2008; @Prasada2000; @Cimpian2010theory; @Cimpian2010].
These studies (both empirical and theoretical) are limited by their assumption that the literal meaning of generics is directly inspectable, that we can interpret our intuitions or findings about generics without needing to formalize the world knowledge that any language user would be bring to interpret a sentence.
In this chapter, I examine a few of these studies to see, if indeed, they are incompatible with a probability-based semantics. 

I will examine two case studies that demonstrate top-down influence of conceptual knowledge on generic endorsement: the origins and dangerousness of properties.
An old intuition with generics is that at least some express properties that are especially enduring and central to a category [@Lyons1977]. 
This *principled connection* between a kind and a property supports both a normative expectation (e.g., *Ks should F*) and explanation of category membership [e.g., *x is a K because it Fs*; @Prasada2006].
@Gelman2007 posit that the way in which an exemplar comes to have a property---the *origins* of a property---can bring about a principled connection between the kind and the property. 
Learning that members of a category (e.g., *dobles*) are born with the property (e.g., born with claws) signals that the kind has a principled connection to the property, which is believed to be what makes the generic ("Dobles have claws") true.
By contrast, observing individuals who acquire the property from the external world (e.g., dobles who find claws on the side of the road and put them on) is less likely to bring about a principled connection, and the generic intuitively is less true. 

Further evidence for how our understanding of generics is tied to our conceptual knowledge comes from the observation that properties that are "striking, appalling, or otherwise gripping" make the generic "...more tolerant [...] to exceptions" [@Leslie2008; p.15].
This argument stems from an attempt to explain why sentences like "Mosquitos carry malaria" and "Tigers eat people" sound like true generic sentences despite the prevalence of the feature in the referent categories being exceptionally low. 
@Cimpian2010 provided empirical support for this claim using generics by testing adult intuitions about novel categories (e.g., "Lorches have dangerous purple feathers"). 
Information about the dangerousness of the property was found to increase participants' propensity to endorse generic sentences when information about the referent prevalence was fixed [e.g., when 30% of lorches have these purple feathers; @Cimpian2010, Expts. 1 & 4]. 

Both @Gelman2007 and @Cimpian2010 measure generic endorsement by having participants judge whether or the sentence is true or false (or, right vs. wrong).
In Chapter 3, we saw how endorsement depends on the referent prevalence (i.e., the prevalence of the property within the referent category) in a nonlinear, relative way that depends in turn on the distribution of prevalence of the property within a set of relevant alternative categories. 
Thus, the minimal computational model presented here already has two distinct mechanisms by which theory-based expectations can influence endorsement: the prevalence prior and the referent prevalence.
Prevalence prior distributions reflect complex structure (often manifesting as multi-modal distributions) and can change dramatically between properties of different types (e.g., biological vs. accidental properties; Ch. 2, Expt. 1; Ch. 3, Expt. 1, Expt. 2) and even within properties that are all of the same conceptual type (e.g., biological properties; Ch. 2, Expt. 2l Ch. 3, Expt. 2). 
Second, referent prevalence is not the objective frequency of the property among actual members of the category in the world, as is assumed in other studies.
Instead, the prevalence that matters for determining the truth or falsity of a generic is a subjective, predictive probability that exists in the mind of the speaker.
(Frequency information is relevant insofar as it informs a speaker's beliefs about the property or event's probability of occurring in the future.)
In our experiments on habitual endorsement (Ch. 3, Expt. 2c), we showed how endorsement patterns can easily be divorced from the objective, present frequency, even taking into account the prior distribution over prevalence.
In those experiments, participants' predictions about the future are what mediated their endorsement of habituals (though again, in a manner relative to the prevalence prior). 

We revisit the effects of property origins and property dangerousness through the computational lens of this dissertation.
First, if referent prevalence is what matters for generic endorsement, then the *pricipled connections* thought to result from learning intrinsic property origins in @Gelman2007 would matter only insofar as it increases the subjective probability that a future instance of the category would have the property. 
Second, if information about dangerousness is argued to influence generic endorsement in a way independent of prevalence, then it must be shown that information about dangerousness does not alter the prevalence prior.
We test these assumptions in this chapter.

We first replicate the effects shown in @Gelman2007 and @Cimpian2010 (Expt. 4).
We then design paradigms to measure the predictive prevalence and prevalence priors, respectively. 
We find that the endorsement patterns in these experiments can be accounted for by changes in the underlying prevalence representations that the generic endorsement model posits.

# Experiment 1: Property origins

So far, we have shown that property prevalence is sufficient to formalize the semantics of generic statements as an underspecified scalar denotation.
But what is property prevalence?
If generic language is truly conveying generalizations, it would be useful for it to reflect expectations, not just the current statistics in the world [cf., @Leslie2008].
The current frequency of a property is often a good indicator of future frequency, yet the statistics at any particular moment can be distorted by spurious events.
The causal history of a property should also be taken into account when determining whether the property will be present in future situations.
<!-- Does generic language communicate prevalence in terms of past frequency or future expectations? -->


@Gelman2007 found that adult endorsements of novel generics were sensitive to the origins of the property (i.e., whether or not the creatures were born with or acquired the property through experience).
In their paradigm, participants are told a story about a novel creature (e.g., dobles) and a property of that kind (e.g., have claws).
After being told the origins of the property (i.e., dobles were either born with claws, or found claws and put them on), participants are told about an event that either causes the property to disappear (e.g., they drank a chemical and their claws fell off) or that leaves the property intact (e.g., they drank a yummy drink and felt happy).
The final display of the experiment shows the novel category in their current state: Dobles either with or without claws (depending on the outcome of the event).
@Gelman2007 found that participants' judgments of the generic (e.g., "Dobles have claws") were *insensitive* to the current state (i.e., the outcome of the drinking event: property maintained vs. lost): Participants fully-endorsed the generic when it was in-born, and rejected it when it was acquired.

In Experiment 1a, we use a paradigm similar to that of @Gelman2007 to replicate the effect of property origins on generic endorsement.
We replicate the effect of property origins, but also, discover an effect of the event outcome.
In Experiment 1b, we alter the dependent measure to measure *predictive prevalence*: participants' expectations that future instances of the kind will have the property.
We find that, consistent with our hypothesis, knowledge of the property influences predictive prevalence in such a way that tracks both the replicated main effect of property origins as well as the novel effect of current state.
Furthermore, predictive prevalence tracks with subtle item-level differences, further indicating that it is an intermediate representation between conceptual knowledge and generic endorsement.

## Experiment 1a: Endorsement task

The design of this experiment is based on a study reported in @Gelman2007 with slight modifications.

### Method

#### Participants

We recruited 80 participants over MTurk.  
The sample in @Gelman2007 was 14 undergraduates.
The experiment took about 3 minutes and participants were compensated \$0.35.
<!-- None of the participants completed Expt. 1b as well. -->

#### Procedure and materials

```{r doblesExpt, fig.cap="Overview of Expt. 1 (intrinsic origins, property lost condition shown) A: Participants are first introduced to ten identical exemplars of a novel categories, either with or without a property (here, shown with the target property of being red). B: The origins of the property are described, either they are born with the property or the acquire it through extrinsic means (born with property shown). C: The event is described and event outcome shown (here, property is lost). D: Participants evaluate the generic with exemplars present."}
fig.dobles.1 <- ggdraw() + draw_image("figs/dobles-expt-1a.jpeg", scale = 0.9) +
  theme(plot.margin = unit(c(2,0,0,0), "pt"),
        panel.background = element_rect(colour = "black", size=1))
fig.dobles.2 <- ggdraw() + draw_image("figs/dobles-expt-2a.jpeg", scale = 0.9)+
  theme(plot.margin = unit(c(2,0,0,0), "pt"),
        panel.background = element_rect(colour = "black", size=1)) 
fig.dobles.3 <- ggdraw() + draw_image("figs/dobles-expt-3a.jpeg", scale = 0.95)+
  theme(plot.margin = unit(c(2,0,0,0), "pt"),
        panel.background = element_rect(colour = "black", size=1))
fig.dobles.4 <- ggdraw() + draw_image("figs/dobles-expt-4a.jpeg", scale = 0.95)+
  theme(plot.margin = unit(c(2,0,0,0), "pt"),
        panel.background = element_rect(colour = "black", size=1))

plot_grid(
  fig.dobles.1,
  fig.dobles.2,
  fig.dobles.3,
  fig.dobles.4,
  nrow = 2, labels = c("A","B", "C", "D")
)
```

On each trial, participants read a vignette about a novel creature. For instance,

> These are dobles. [picture of ten dobles with claws] Here is how they grew. They grew up with claws. First they were born, then they got bigger, then they were full size. [picture of a doble with claws, getting bigger and bigger; in some vignettes, the animal was first shown hatching out of an egg with the relevant property already visible] Then one day they drank a bad chemical. They got very sick and this is how they looked. [picture of ten dobles without claws]

The trial proceeded by participants reading the text, and clicking a button to continue to the next part of the story at which time, the images changed according to the example above (Figure\ \@ref(fig:doblesExpt)).

Participants completed four trials: two in which the creatures are born with the property (*intrinsic origins*) and two in which the creatures are shown discovering and acquiring the property (*extrinsic origins* e.g., painting themselves brown).
Property origins were crossed with either the creatures drinking a "bad chemical" and losing the property, or drinking a "yummy drink" and maintaining the property.
The outcome of this event determined the final presentation of images that the participant saw (e.g., either ten dobles with claws or ten without).

With the final display of dobles present (either property lost or maintained), we measured endorsement by asking participants: "Do you agree or disagree that: *generic statement* (e.g., Dobles have claws)".
Participants responded by choosing one of two radio buttons corresponding to agree or disagree.

We used two different types of properties: colors (e.g., "Dobles are green.") and body parts (e.g., "Dobles have claws.").
For each type of property, there were approximately eight different property values (different colors or different body parts for different creatures).
The creatures were either birds, bugs, or fish, with randomly sampled physical dimensions (e.g., sizes of body or tail).
The experiment in full can be viewed at \url{http://stanford.edu/~mtessler/generics/experiments/predictive/predictive-1.html}.

#### Results

```{r load dobles regression results}
load("cached_results/brm_dobles_2way_randInt-subj-proptype.RData") # brm.interaction.fit
load("cached_results/brm_doblesPrev_2way_randInt-subj-proptype.RData") # brm.interaction.prev.fit
brm.interaction.fit.summary <- summary(brm.interaction.fit)
brm.interaction.prev.fit.summary <- summary(brm.interaction.prev.fit)
format_regression_effects <- function(brm_summary, fixed_effect_name, n_digits = 3){
   e1 <- brm_summary[["fixed"]][[fixed_effect_name, "Estimate"]]
   e_lower <- brm_summary[["fixed"]][[fixed_effect_name, "l-95% CI"]]
   e_upper <- brm_summary[["fixed"]][[fixed_effect_name, "u-95% CI"]]
   return(paste(
     format(e1, digits = n_digits), " [", 
     format(e_lower, digits = n_digits), ", ", 
     format(e_upper, digits = n_digits), "]", sep = ""))
}
```

One participant was excluded for self-reporting a native language other than English, leaving n=79 for these analyses.
@Gelman2007 found that participants endorsed the generic when the property was inborn but not when the property was acquired through extrinsic means (i.e., an effect of *property origins*), regardless of how the event turned out (property lost vs. maintained). 
Figure\ \@ref(fig:predictiveDoblesResults)A shows the proportion of participants who endorsed the generic under the four experimental conditions.
To evaluate the effects, we built a Bayesian mixed-effects Bernoulli regression model with fixed-effects of property origins, current state, and their interaction with a random intercept by participant and by property type (color vs. body part). 
As is evident in Figure\ \@ref(fig:predictiveDoblesResults)A, there were effects of both property origins and of event outcome such that participants were more likely to endorse the generic when it was a property that was in-born ($\beta =$ `r format_regression_effects(brm.interaction.fit.summary, "originsintrinsic", 3)`) and when it was a property that was maintained following the drinking event ($\beta =$ `r format_regression_effects(brm.interaction.fit.summary, "event_outcomemaintained", 3)`). 
<!-- The 95% credible intervals indicate that there is at least a 95% probability that the regression coefficients are greater than 0. -->
The interaction term was not different from zero ($\beta =$ `r format_regression_effects(brm.interaction.fit.summary, "originsintrinsic:event_outcomemaintained", 3)`).


<!-- In the original study, the first sentence of each vignette used the possessive "my": "These are my dobles.". -->
<!-- To see whether this second main effect could be attributed to a subgroup of participants making their judgments based only on the final display (which showed creatures with or without the property, depending on the event outcome), we categorized participants according to their pattern of responses.  -->
<!-- Just as many participants endorsed the generic based on the final screen alone (*Only current state*: 19) as there were basing their endorsement on both the outcome and the origins (*Both outcome and origins*: 16). -->
<!-- 36 participants based their responses on only the origins, and 9 participants exhibited some other pattern of responses. -->
<!-- Thus, it seems this effect is not due to a subgroup of participants basing their responses on only the final screen. -->

As an exploratory analysis, we looked to see if these effects were modulated by the kind of property in question (skin color vs. body part). 
Figure\ \@ref(fig:predictiveDoblesResultsProperty)A shows the endorsements split up by the type of property in question.
There is suggestive evidence that the endorsement of a generic for skin color properties (e.g., "Dobles are green") seems to be less sensitive to the outcome of the event (i.e., dobles losing their color as a result of drinking a chemical).

The fact that participants were sensitive to the outcome of the event when endorsing the generic suggests that their beliefs about the stability of these properties influenced their judgments.
For example, participants may believe that the fact that the property can be lost based on drinking a chemical indicates that the property is relatively unstable feature, analagous to heads of hair on adult male humans.
Similarly, the existence of properties in the environment that individuals can come across and acquire is perhaps some evidence that the this external cause of the property is relatively stable. 
The exploratory analysis is consistent with this if participants believe skin color to be a less malleable property than the body part stimuli.
If that is what is leading more participants to endorse the generics about skin color, we would expect to see it reflected in their predictions about future instances of the category having the property, which we measure in Expt. 1b.

The fact that we find a second main effect of event outcome in addition to property origins, while the original only found only a main effect of origins, makes it worth remarking on the differences between our paradigm and the original study by @Gelman2007.
At the end of each vignette, the original study had participants judge two statements in counterbalanced order: "Do my dobles have claws?" and "Do dobles have claws?" (the creatures on the displays were first introduced as "my dobles", whereas in our paradigm, they were simply "dobles").
This explicit contrast may have led participants to provide different answers in the conditions where the property origins conflicted with the event outcome.
Another possibility is that the original study was underpowered to detect the effect of event outcome: The original sample size was 14; ours is 80. 


```{r predictiveDoblesResults, fig.width=8, fig.cap="Expt. 1 results. A: Generic endorsement task (Expt. 1a). B:Predicted prevalence task (Expt. 1b). Error bars represented bootstrapped 95% confidence intervals.", fig.asp=0.36}
load(file = "cached_results/dobles_endorsement_cis.RData") # d.origins.filtered.summary, d.origins.filtered.property.summary
load(file = "cached_results/dobles_prevalence_cis.RData") # d.origins.prev.filtered.summary, d.origins.prev.filtered.property.summary


bar_width = 0.5

fig.dobles.endorsement <- ggplot(d.origins.filtered.summary, aes(x = origins, y = mean, ymin = ci_lower, ymax = ci_upper, 
                                       fill = event_outcome))+
  geom_bar(stat = 'identity', position = position_dodge(bar_width), color = 'black', width = bar_width)+
  scale_fill_manual(values = c("white", "grey45"))+
  geom_errorbar(position = position_dodge(bar_width), width = bar_width/1.5)+
  scale_y_continuous(limits = c(0, 1), breaks = c(0, 0.5, 1))+
  ylab("Proportion endorsement")+
  xlab("Property origins")+
  guides(fill = F)

fig.dobles.prevalence <- ggplot(d.origins.prev.filtered.summary, 
                                aes(x = origins, y = mean, ymin = ci_lower, ymax = ci_upper, 
                                       fill = event_outcome))+
  geom_bar(stat = 'identity', position = position_dodge(bar_width), color = 'black', width = bar_width)+
  scale_fill_manual(values = c("white", "grey45"))+
  geom_errorbar(position = position_dodge(bar_width), width = bar_width/1.5)+
  scale_y_continuous(limits = c(0, 1), breaks = c(0, 0.5, 1))+
  ylab("Predicted prevalence")+
  xlab("Property origins")+
  guides(fill = guide_legend(title = "Event outcome",reverse = T))

cowplot::plot_grid(
  fig.dobles.endorsement,
  fig.dobles.prevalence,
  nrow = 1,
  labels = c("A", "B"),
  rel_widths = c(1, 1.5)
)

```




```{r predictiveDoblesResultsProperty, fig.width=9, fig.cap="Expt. 1 exploratory analysis breaking down results by the type of property (skin color vs. body part). A: Generic endorsement task (Expt. 1a). B: Predicted prevalence task (Expt. 1b). Error bars represented bootstrapped 95% confidence intervals. ", fig.asp=0.35}
fig.dobles.endorsement.property <- ggplot(d.origins.filtered.property.summary, 
                                          aes(x = origins, 
                                              y = mean, ymin = ci_lower, ymax = ci_upper, 
                                       fill = stim_proptype))+
  geom_bar(stat = 'identity', position = position_dodge(bar_width), color = 'black', width = bar_width,
           alpha = 0.8)+
  #scale_fill_manual(values = c("white", "grey45"))+
  scale_fill_solarized()+
  geom_errorbar(position = position_dodge(bar_width), width = bar_width/1.5)+
  scale_y_continuous(limits = c(0, 1), breaks = c(0, 0.5, 1))+
  ylab("Proportion endorsement")+
  xlab("Property origins")+
  facet_wrap(~event_outcome, nrow = 1)+
  guides(fill = F)+
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))

fig.dobles.prevalence.property <- ggplot(d.origins.prev.filtered.property.summary, 
                                         aes(x = origins, y = mean, ymin = ci_lower, ymax = ci_upper, 
                                       fill = stim_proptype))+
  geom_bar(stat = 'identity', position = position_dodge(bar_width), color = 'black', width = bar_width,
           alpha = 0.8)+
  scale_fill_solarized()+
  geom_errorbar(position = position_dodge(bar_width), width = bar_width/1.5)+
  scale_y_continuous(limits = c(0, 1), breaks = c(0, 0.5, 1))+
  ylab("Predicted prevalence")+
  xlab("Property origins")+
  theme(axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))+
  facet_wrap(~event_outcome, nrow = 1)+
  guides(fill = guide_legend(title = "Property type",reverse = T))


cowplot::plot_grid(
  fig.dobles.endorsement.property,
  fig.dobles.prevalence.property,
  nrow = 1,
  labels = c("A", "B"),
  rel_widths = c(1, 1.3)
)
```

<!-- reported a main effect of property origins with no effect of the current state. -->

<!-- \red{ clean up } -->
<!-- %                                         Estimate Std. Error z value        Pr(>|z|)     -->
<!-- %(Intercept)                               -2.9444     0.5130  -5.740 0.0000000094624 *** -->
<!-- %event_outcomemaintained                    2.6931     0.5603   4.807 0.0000015342262 *** -->
<!-- %originsintrinsic                           3.6753     0.5658   6.496 0.0000000000824 *** -->
<!-- %event_outcomemaintained:originsintrinsic   0.2396     0.9400   0.255           0.799     -->

<!-- Our pragmatics model with the elicited predicted prevalence from Expt. 1a made two novel predictions for this experiment: (1) in addition to a main effect of origins, we would find a main effect of event outcome; (2) this effect would be stronger for body part properties than for color properties. -->

<!-- As predicted, we found two main effects (Figure \ref{fig:dobles}b, top). -->
<!-- The main effect of property origins replicated ($\beta=3.6, SE=0.57, z=6.5, p<1\text{e}10$): participants were more likely to endorse the generic when it was about a property that the creature was born with. -->
<!-- In addition, we find a second main effect of event outcome  -->
<!--  ($\beta = 2.69, SE = 0.56, z=4.8, p<1\text{e}5$): participants were more likely to endorse the generic when the property was maintained than when it was lost. -->



<!-- \begin{table}[] -->
<!-- \centering -->
<!-- \begin{tabular}{@{}lllll@{}} -->
<!-- \toprule -->
<!--   & Only origins & Only outcome & Both & Neither \\ \midrule -->
<!-- n & 36           & 19           & 16   & 9       \\ \bottomrule -->
<!-- \end{tabular} -->
<!-- \caption{Numbers of participants ($N=80$) who made their generic endorsement based on different factors.} -->
<!-- \label{tab:dobles} -->
<!-- \end{table} -->




<!-- \begin{figure*} -->
<!-- \begin{tabular}{l l} -->
<!-- (a) $S_2$ model predictions & (b) Human endorsement of generic statements \\ -->
<!-- \\ -->
<!-- \centering -->
<!--     \includegraphics[width=0.5\columnwidth]{figs/dobles-model.pdf} & -->
<!--         \includegraphics[width=0.5\columnwidth]{figs/dobles-results.pdf} \\ -->
<!--       \includegraphics[width=0.5\columnwidth]{figs/dobles-model-byItem.pdf} & -->
<!--       \includegraphics[width=0.5\columnwidth]{figs/dobles-byItem-results.pdf} \\ -->
<!-- \end{tabular} -->
<!--     \caption{ -->
<!--     Prevalence is a predictive probability. -->
<!--     (a) Truth judgment model predictions given the predicted prevalence elicited in Expt.~3a. -->
<!--     (b) Average endorsement of the generic statement in Expt.~3b (replication of Gelman and Bloom, 2007). -->
<!--     Bottom row shows data and predictions broken down by property type. -->
<!--   } -->
<!--   \label{fig:dobles} -->
<!-- \end{figure*} -->


## Experiment 1b: Predictive prevalence elicitation

In this experiment, we test the prediction that the effect of property origins and current state observed in Expt. 1a can be explained by differences in participants' predictions about the property in future instances of the category.

### Method

#### Participants

We recruited 80 participants over MTurk.  
The experiment took about 3 minutes and participants were compensated \$0.35.

#### Procedure and materials

The procedure and materials are exactly the same as in Expt. 1a, with the exception of the dependent measure.
After reading the vignette and being shown the final screen of exemplars, we measured *predictive prevalence* by telling participants: "A new doble was born today. When it becomes full grown, how likely is it that it would *have property* (e.g. have claws)?"
Participants responded using sliders ranging from "very unlikely" to "very likely".

### Results

3 participants were excluded for self-reporting a native language other than English, leaving n=77 for these analyses.
The computational model predicts that generic endorsement is modulated by a speaker's degree of belief in the property being present in future instances of the category. 
In order to evaluate this hypothesis, we built a Bayesian mixed-effects beta regression model with fixed-effects of property origins, current state, and their interaction with a random intercept by participant and by property type (color vs. body part). 
As is evident in Figure\ \@ref(fig:predictiveDoblesResults)B, participants predicted with more certainty that the property would be present in future instances when the property that was in-born ($\beta =$ `r format_regression_effects(brm.interaction.prev.fit.summary, "originsintrinsic", 2)`) and when it was a property that was maintained following the drinking event ($\beta =$ `r format_regression_effects(brm.interaction.prev.fit.summary, "event_outcomemaintained", 2)`). 
<!-- The 95% credible intervals indicate that there is at least a 95% probability that the regression coefficients are greater than 0. -->
The interaction term was not different from zero ($\beta =$ `r format_regression_effects(brm.interaction.prev.fit.summary, "originsintrinsic:event_outcomemaintained", 2)`).

Again, as an exploratory analysis, we break the items down by type of property (skin colors vs. body parts). 
Figure\ \@ref(fig:predictiveDoblesResultsProperty)B shows the parallel pattern of responses, wherein predictions about skin color were less sensitive to the event outcome than predictions about body parts. 

To confirm that our computational model accomodates the generic endorsement data (Expt. 1a), we use the predicted prevalence ratings (Expt. 1b) as the referent prevalence $p$ that the speaker model is trying to communicate: $S(u\mid p)$, and examine the model's predicted endorsements, using the body part and skin color priors elicited in Ch. 2 (Expt. 1a) as the priors in this model.
The generic endorsement model predictions track closely with the empirical generic endorsement data based on origins, outcome, and property type (Figure\ \@ref(fig:dobles-model-scatter); $r^2(8) = 0.96$).^[
 <!-- By extension, the generic endorsement model predictions also track closely with the predicted prevalence ratings. -->
 In this instance, the computational model's predictions are very similar to the predicted prevalence ratings, even though the model predictions depend upon the listener's prevalence prior distribution.
  Since the properties are both biological in nature and, as measured in Ch. 2 (Expt. 1a), are both relatively broad (high variance), we do not observe substantial interactions with the prevalence prior.
]
This is strong evidence that beliefs about property origins influences generic endorsement via influencing beliefs about future prevalence. 


<!-- The computational model's predictions are not necessarily the same as the predicted prevalence values, but instead depend upon the listener's prevalence prior distribution.  -->
<!-- Since the properties are only of two types (color and body part) and both biological in nature, we do not expect substantial interactions with the prevalence prior; futher, since the priors for body part and color priors elicited in Ch. 2. (Expt. 1a) are both relatively broad (high variance), we expect predicted generic endorsement to track predictive prevalence to a large degree. -->

<!-- We, thus, elaborate our theory: -->
<!-- The semantics of generics can be understood as a threshold on property prevalence, and this prevalence is a speaker's subjective belief about what is likely to be the case in the future. -->




```{r dobles-model-scatter, fig.width=6, fig.cap="Computational model predictions for generic endorsements (Expt. 1a) based on predicted prevalence ratings (Expt. 1b). Model predictions also track the predicted prevalence ratings to a high degree."}
ggdraw() + draw_image("figs/dobles-model-data-scatter.pdf", scale = 1)
```



<!-- The average predicted prevalences for the four experimental conditions are shown in Table \ref{tab:predictive}. -->
<!-- We observe a main effect of origins, such that when participants read that the creatures had the property from birth, future creatures  are much more likely to have the property as compared to when the property is acquired. -->
<!-- We see that, in our paradigm, participants are also sensitive to the outcome of the event  (property lost or maintained). -->
<!-- This is surprising given @Gelman2007's reporting of no effect of the event outcome on endorsement. -->
<!-- When participants observe a creature who loses the property by drinking a chemical, they report future members of the category are less likely to have the property. -->
<!-- This inference could be driven by inferences about the property (e.g., learning that the property is an unstable property because you can lose it simply by drinking something) or by inferences about the event (e.g., learning that the "chemical drinking" event is within the space of possibilities for dobles, and thus it could happen in the future). -->


<!-- This is because both color and body part priors are relatively broad, and hence when the property is (predicted to be) more prevalent, the generic has a higher probability of applying (see schematic predictions from Figure \ref{fig:schematic-unif} ``have wings'' for comparison). -->
<!-- We also see that the model predicts a subtle by-item difference, such that the influence of the event outcome (lost or maintained) on generic endorsement is predicted to be stronger for body parts than for color terms (Figure \ref{fig:dobles}a, bottom). -->
<!-- This prediction is mostly due to the predicted prevalence for the conflict conditions (intrinsic-lost and extrinsic-maintained) being subtly different (Table \ref{tab:predictive}, right-most columns). -->



<!-- \begin{table} -->
<!-- \centering -->
<!-- \begin{tabular}{l|l|r|r|r} -->
<!-- \hline -->
<!-- Origins & Event Outcome & Collapsed Mean [95\% CI]  & Color  [95\% CI] & Body Part [95\% CI] \\ -->
<!-- \hline -->
<!-- Extrinsic & Lost  & 0.15 [0.10, 0.21]& 0.13 [0.07, 0.21] & 0.17 [0.09, 0.26] \\ -->
<!-- \hline -->
<!-- Extrinsic & Maintained & 0.32 [0.24, 0.39] & 0.24 [0.16, 0.35] & 0.38 [0.27, 0.50] \\ -->
<!-- \hline -->
<!-- Intrinsic & Lost  & 0.69 [0.62, 0.76] & 0.73 [0.63, 0.83] & 0.66 [0.56, 0.75] \\ -->
<!-- \hline -->
<!-- Intrinsic & Maintained  &0.95 [0.94, 0.97] & 0.96 [0.94, 0.98] & 0.94 [0.91, 0.97] \\ -->
<!-- \hline -->
<!-- \end{tabular} -->
<!-- \caption{Predicted prevalence for the four experimental conditions of Expt.~3a. Right two columns show the summaries broken down by the two types of properties used in the experiment.} -->
<!-- \label{tab:predictive} -->
<!-- \end{table} -->

<!-- We use these predicted probabilities as the prevalence $p$ that the speaker model is trying to communicate: $S(u\mid p)$, and examine the model's predicted truth judgments. -->
<!-- We explore the model's predictions for each origin and event outcome, as well as when the data is split by property type (color vs. body parts).  -->
<!-- For priors $P(p)$, we use the body part and color priors elicited in Ch. 2., Expt. 1a. -->
<!-- We see that the model predictions track closely the predicted prevalence (Figure \ref{fig:dobles}a, top, compare with predicted prevalence in Table \ref{tab:predictive}). -->
<!-- This is because both color and body part priors are relatively broad, and hence when the property is (predicted to be) more prevalent, the generic has a higher probability of applying (see schematic predictions from Figure \ref{fig:schematic-unif} ``have wings'' for comparison). -->
<!-- We also see that the model predicts a subtle by-item difference, such that the influence of the event outcome (lost or maintained) on generic endorsement is predicted to be stronger for body parts than for color terms (Figure \ref{fig:dobles}a, bottom). -->
<!-- This prediction is mostly due to the predicted prevalence for the conflict conditions (intrinsic-lost and extrinsic-maintained) being subtly different (Table \ref{tab:predictive}, right-most columns). -->

<!-- The model thus makes two novel predictions for generic endorsement in the paradigm by @Gelman2007. -->
<!-- We predict that in addition to the main effect of origins, we should see a second main effect of event outcome. -->
<!-- Second, we predict that this effect should be slightly stronger in the case of color properties than in the case of body part properties. -->

<!-- ## Discussion -->




# Experiment 2: The impact of strikingness

@Leslie2007 brings our attention to examples like the following:

1. Sharks attack bathers.
2. Rottweilers maul children. 
3. Mosquitos carry the West Nile Virus.

In each case, the property is somehow *striking, alarming,* or *dangerous*:

> The examples... have something in common: In all of them, the sentence attributes harmful, dangerous, or appalling properties to the kind. More generally, if the property in question is the sort of property of which one would be well served to be forewarned, even if there were only a small chance of encountering it, then generic attributions of the property are intuitively true. (2008, p.15)

@Leslie2008 argues that these generics are reasonable utterances, even though the actual prevalence of the property is quite low (e.g., less than 1% of mosquitos carry the West Nile Virus), because the property is *striking*. 
@Cimpian2010 (Expt. 1) found that generics about novel categories (of the kind seen in Chapter 4) are endorsed more highly when the property being predicated is *distinctive and dangerous*. 
In a follow-up (Expt. 4), the increase in endorsement was found for properties that were described independently as either distinctive or dangerous.

The information-theoretic communicative model predicts that these differences in endorsements are mediated by corresponding differences in the prevalence prior distributions. 
Indeed, we have already seen in Chapter 3 (generic endorsement) that statements about familiar categories like Sentences 1-3 are endorsed despite low referent prevalence because the prevalence prior distribution reflects that of a distinctive property.
That is, because most animals do not carry the West Nile Virus, and even among those that do, the prevalence is quite low, the endorsement model is willing to assert the generic sentence even though very few mosquitos carry the West Nile Virus. ^[
  An alternative possibility, still within the space of our endorsement model and one that @Leslie2008 suggests, is that a speaker's perception of the prevalence of the feature is altered by virtue of its dangerousness [@Rothbart1978].
  This explanatory mechanism would be the same as the one we explored in Expt. 1.
]

Here, we examine if the relationship between striking or dangerous properties and prevalence priors also holds for generics about novel  categories using the set of dangerous items used by @Cimpian2010. 
We reverse the order of our standard experimental procedure.
First, we replicate the findings of @Cimpian2010 Expt. 4, to try to find the influence of dangerousness information on generic endorsement.
Then, we run a prior elicitation paradigm and use our computatoinal model to jointly model both sets to see if these differences in endorsements can be traced back to differences in the prevalence prior distributions. 

## Experiment 2a: Truth judgment task

This experiment is a replication of @Cimpian2010 Expt. 4. 

### Method

#### Participants

We recruited 40 participants over MTurk. 
The experimental design is very similar to @Cimpian2010 (Expt. 4), and we chose to have a sample size at least twice as large as the original study (original n=15). 
All participants were native English speakers. 
The experiment took about 5 minutes and participants were compensated \$0.60.

#### Materials

The materials were taken from @Cimpian2010 (Expt. 4).
Properties were either described as dangerous, distinctive, or neither. 


#### Procedure

In order to get participants motivated to reason about novel kinds, they were told they were the resident zoologist of a team of scientists on a recently discovered island with many unknown animals; their task was to provide their expert opinion on questions about these animals.
On each trial, participants were given a statement about a property's prevalence within a novel kind (*referent prevalence*; e.g. "50% of feps have yellow fur."). 
Participants were then asked whether or not they agreed or disagreed with the corresponding generic sentence (e.g. "Feps have yellow fur.").
Referent prevalence varied between 10, 30, 50, 70, and 90%.

The experiment consisted of thirty trials. Participant saw each prevalence level twice paired with each of the three kinds of property (5 prevalence levels x 2 repetitions x 3 property types).

### Results

## Experiment 2b: Prior elicitation

### Method

#### Participants

We recruited 80 participants over MTurk. 
The experiment took about X minutes and participants were compensated \$Y.

#### Materials and procedure

The experiment was divided into two blocks. 
In the first block, participants were told that on this island there were one thousand (1000) different species of animals. They were asked to make a prediction about how many different species of animals they thought would have the property.
In the second block, participants were told they scientists came across a particular instance of a novel category with the property (e.g., "Scientists today saw a glippet. It had *property*") and asked to predict how many other instances of the category had the property (e.g., "What percentage of other glippets do you think *have property*?").
We did not randomize blocks because the second asks participants to imagine a category with the property; this would likely bias judgments about the number of categories with the property (the first block).

To serve as an attention check, participants were shown a list of ten properties following the last block of the experiment. 
They were asked to select all and only the properties they had seen. 
The list was composed of five seen properties and five distractor properties which were very similar to the seen properties (e.g., seen properties = \{*yellow legs*, *blue ears*, *pink teeth*, ...\}, distactor properties = \{*red arms*, *purple eyes*, *copper fingers*,...\}).

The materials were the same as in Expt. 2a. 

### Results

```{r load dangerous priors results}
# brms.priors.zero_inf_beta_max, brms.priors.zero_inf_beta_randInt
load(file = "cached_results/dangerous-priors-randIntSlope.RData")
load(file = "cached_results/dangerous-priors-sansInt-randIntSlope.RData") #brms.priors.zero_inf_beta_max.sansInt
load(file = "cached_results/dangerous-priors-projectibility-randIntSlope.RData")
# brms.priors.project.zeroone_beta_max
brms.priors.zero_inf_beta_max.summary <- summary(brms.priors.zero_inf_beta_max)
brms.priors.zero_inf_beta_max.sansInt.summary <- summary(brms.priors.zero_inf_beta_max.sansInt)
brms.priors.project.zeroone_beta_max.summary <- summary(brms.priors.project.zeroone_beta_max)
```

Our primary analysis concerns whether or not dangerousness and distinctiveness both influence the number of species predicted to have the property in the same way.
In particular, we predict that both dangerousness and distinctiveness will similarly decrease the number of species expected to have the property (i.e., they both increase the distinctiveness of the property).
To test this, we transformed the raw numerical responses (numbers between 0-1000) into proportions by dividing by 1000 and built a Bayesian regression model using a "zero inflated beta" linking function.
Zero-inflated Beta is appropriate because our dependent measure is proportions between 0 and 1 and because pilot testing revealed the response distributions to be highly non-normal, with substantial probability mass at exactly 0 (i.e., 0 species have the property). 
We use the maximal mixed effects structure, which has by-participant and by-item random effects of intercept and effect of property type.^[
The model syntax is: `response ~ property_type +  (1 + property_type | participant) +  (1 + property_type | property)`, where property_type is either dangerous, distinctiveness, or neither, and property are individual items (e.g., purple feathers).
]

In keeping with our prediction, both distinctive properties ($\beta_{distinctive} = `r format_regression_effects(brms.priors.zero_inf_beta_max.summary, "property_typedistinctive")`$) and dangerous properties ($\beta_{dangerous} = `r format_regression_effects(brms.priors.zero_inf_beta_max.summary, "property_typedangerous")`$) were expected to be present in fewer categories in comparison to the control condition (i.e., properties present without any further information). 
Figure\ \@ref(fig:dangerousPriorsResults) shows the empirical distribution of responses for both questions, as well as the means. 
The fact that such properties are present in fewer categories relaxes their truth conditions, leading to increased endorsements at lower prevalence levels, as can be seen by the computational model predictions based on these empirically elicited priors \red{(Figure)}.
Thus, the influence of dangerous properties on endorsements of generic sentences [at least the examples used by @Cimpian2010] can be attributed purely to the statistics of the feature.
Dangerous properties are distinctive properties, and the absolute estimates were not appreciably different from each other  ($\beta_{distinctive} = `r format_regression_effects(brms.priors.zero_inf_beta_max.sansInt.summary, "property_typedistinctive")`$, $\beta_{dangerous} = `r format_regression_effects(brms.priors.zero_inf_beta_max.sansInt.summary, "property_typedangerous")`$) 

As a secondary analysis, we were interested as to whether dangerous properties were also more *projectible*, as hypothesized by @Leslie2008.
Admittedly, our paradigm is not the only way one would want to test the projectibility hypothesis, but it is one way. 
We built a similar regression model, which used a "zero and one inflated beta" linking function, which independently models the responses of exactly 0% and exactly 100%, because these are undefined under the beta distribution.
The model had a maximal random-effects structure similar to that for the analysis of the distinctiveness measure.
Though the effect of dangerousness leading to higher ratings of projectibility was numerically positive, the credible intervals were too broad to draw a conclusion ($\beta_{dangerousness} = `r format_regression_effects(brms.priors.project.zeroone_beta_max.summary, "property_typedangerous", 2)`$) and similarly for distinctive properties ($\beta_{distinctive} = `r format_regression_effects(brms.priors.project.zeroone_beta_max.summary, "property_typedistinctive", 2)`$).
Thus, we do not have evidence to support the claim that dangerousness leads to stronger projectibility, operationalized in measured prevalence based on observing a single instance with the feature [cf., @Rothbart1978].

```{r dangerousPriorsResults, fig.width=8, fig.cap="Caption", fig.asp=0.6}
load(file = "cached_results/dangerous-priors-filtered.RData") # d.priors.filtered 


fig.dangerous.priors.numcats <- d.priors.filtered %>%
  filter(trial_type == "num_categories") %>%
           mutate(property_type = factor(property_type,
                                        levels = c("bare", "distinctive", "dangerous"),
                                        labels = c("control", "distinctive", "dangerous"))) %>%
  ggplot(., aes( x = response ))+
  geom_histogram(bins = 20, color = 'black', fill = 'white',
                aes(y=(..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..]))+
  scale_x_continuous(limits = c(0, 20), breaks = c(0, 10, 20))+
  scale_y_continuous(limits = c(0, 0.85), breaks = c(0, 0.4, 0.8))+
  facet_wrap(~property_type)+
  ylab("proportion of responses")+
  xlab("predicted number of categories with property")

fig.dangerous.priors.projectibility <-d.priors.filtered %>%
  filter(trial_type == "projectibility") %>%
           mutate(property_type = factor(property_type,
                                        levels = c("bare", "distinctive", "dangerous"),
                                        labels = c("control", "distinctive", "dangerous"))) %>%
  ggplot(., aes( x = response ))+
  geom_histogram(bins = 20, color = 'black', fill = 'white',
                aes(y=(..count..)/tapply(..count..,..PANEL..,sum)[..PANEL..]))+
  scale_x_continuous(breaks = c(0, 50, 100))+
  scale_y_continuous(limits = c(0, 0.52), breaks = c(0, 0.5))+
  facet_wrap(~property_type)+
  ylab("proportion of responses")+
  xlab("predicted number of instances of category with property")


bar_width = 0.6
fig.dangerous.priors.bars <- ggplot(d.prior.summary %>% ungroup() %>%
         mutate(property_type = factor(property_type,
                                        levels = c("bare", "distinctive", "dangerous"),
                                        labels = c("control", "distinctive", "dangerous")),
                trial_type = factor(trial_type,
                                    levels = c("num_categories","projectibility"),
                                    labels = c("Number of categories",
                                               "Number of instances"))), 
       aes( x = property_type,
            #fill = property_type,
                             y = mean,
                             ymin = ci_lower,
                             ymax = ci_upper ))+
  geom_bar(stat = "identity", position = position_dodge(bar_width),
           width = bar_width, color = 'black')+
  geom_errorbar(position = position_dodge(bar_width), width = bar_width/2)+
  #scale_x_discrete()+ 
  xlim("control","distinctive", "dangerous")+
  scale_y_continuous(limits = c(0, 100), breaks = c(0, 50, 100))+
  #scale_fill_solarized()
  facet_wrap(~trial_type, scales = 'free', ncol = 1)+
  theme(axis.title.x = element_blank(),
        axis.text.x = element_text(angle = 45, hjust = 1, vjust = 1))+
  ylab("Mean ratings")

cowplot::plot_grid(
  cowplot::plot_grid( fig.dangerous.priors.numcats, fig.dangerous.priors.projectibility, ncol = 1,
                      labels = c("A","B")),
  fig.dangerous.priors.bars,
  labels = c("", "C"), 
  nrow = 1,
  rel_widths = c(2,1)
)


```


<!-- # Experiment 3: Transient properties -->

# Discussion

## Predictive prevalence and sufficiently long histories

- report on pilot data (n = 15 each):
  - If you were to encounter another doble, how likely is it that it would have claws?
  - There are 100 other dobles on the planet. How many of them do you think have claws?
  - Predictive born today
  - Predictive other side of planet

- relation to "normal" generics approaches

<!-- Include (in the GD) some informal analysis of Cimpian, Gelman, & Brandone (2010), Lang Cogn Process -->


<!-- 

- dangerousness also distorts predictive prevalence?
  - Leslie draws on inspiration about people's predictions about the likelihood of encountering a dangerouesness property (Leslie  2008, Rothbart etal 1978).
  - Also, representativeness heuristic (KT) in bringing rare events to mind.  
  
- does dangerousness infleunce generic understanding beyond rational(ish) probabilities? 
  - the evidence that dangerounsness impacts endorsement is confounded... there is no evidence that dangerousness impacts endorsements outside of the relevant probabilities 
  - Sterken 2015 argues that these statements are false assertions
  - "loose talk" theories
  - what does Leslie have to say about the mechanisms by which dangerous information is connected?
  - Prasada descrbies the "causal connections"
    - is there a difference between "causal" and "principled" connections in our model? (no, the model is agnositc... also no difference for "statistical" connections...)
-->

\newpage

# References


```{r create_r-references}
r_refs(file = "generics.bib")
```

\setlength{\parindent}{-0.5in}
\setlength{\leftskip}{0.5in}
